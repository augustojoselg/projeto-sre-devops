# Projeto SRE Completo - GCP + Kubernetes + Terraform

## üìã **Vis√£o Geral**

Este projeto implementa uma solu√ß√£o completa de **Site Reliability Engineering (SRE)** no Google Cloud Platform (GCP), seguindo as melhores pr√°ticas de DevOps, seguran√ßa e alta disponibilidade. O ambiente √© totalmente provisionado via **Infrastructure as Code (IaC)** usando Terraform.

## üéØ **Objetivos**

- ‚úÖ **Alta Disponibilidade**: Cluster GKE com 1 master e 2 workers
- ‚úÖ **Seguran√ßa**: M√∫ltiplas camadas de prote√ß√£o e compliance
- ‚úÖ **Monitoramento**: Stack completo de observabilidade
- ‚úÖ **APM**: Application Performance Monitoring com Jaeger e Kiali
- ‚úÖ **Logs**: Agrega√ß√£o centralizada com Fluent Bit
- ‚úÖ **Secrets**: Gerenciamento seguro com HashiCorp Vault
- ‚úÖ **Testes**: Testes de estresse com monitoramento integrado
- ‚úÖ **Automa√ß√£o**: CI/CD pipeline completo
- ‚úÖ **Documenta√ß√£o**: README detalhado com explica√ß√µes t√©cnicas

## üèóÔ∏è **Arquitetura**

### **Infraestrutura GCP**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    GCP PROJECT                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ   VPC + Subnet  ‚îÇ  ‚îÇ   GKE Cluster   ‚îÇ  ‚îÇ   Cloud     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ  (1 Master +    ‚îÇ  ‚îÇ   Storage   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - Flow Logs   ‚îÇ  ‚îÇ   2 Workers)    ‚îÇ  ‚îÇ   + KMS     ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ   Cloud NAT     ‚îÇ  ‚îÇ   Load Balancer ‚îÇ  ‚îÇ   DNS       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   + Firewall    ‚îÇ  ‚îÇ   + SSL         ‚îÇ  ‚îÇ   + Domain  ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **Stack de Monitoramento e Observabilidade**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                MONITORING NAMESPACE                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Prometheus      ‚îÇ  ‚îÇ   Grafana       ‚îÇ  ‚îÇ AlertManager‚îÇ ‚îÇ
‚îÇ  ‚îÇ + Metrics       ‚îÇ  ‚îÇ + Dashboards    ‚îÇ  ‚îÇ + Rules     ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ   Jaeger        ‚îÇ  ‚îÇ     Kiali       ‚îÇ  ‚îÇ  Fluent Bit ‚îÇ ‚îÇ
‚îÇ  ‚îÇ + Tracing       ‚îÇ  ‚îÇ + Service Mesh  ‚îÇ  ‚îÇ + Logs      ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **Stack de Seguran√ßa**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                SECURITY LAYERS                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ   Vault         ‚îÇ  ‚îÇ   Cert-Manager   ‚îÇ  ‚îÇ   RBAC      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ + Secrets       ‚îÇ  ‚îÇ + SSL/TLS        ‚îÇ  ‚îÇ + Policies  ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Network Policy  ‚îÇ  ‚îÇ Pod Security    ‚îÇ  ‚îÇ Cloud Armor ‚îÇ ‚îÇ
‚îÇ  ‚îÇ + Firewall      ‚îÇ  ‚îÇ + Admission     ‚îÇ  ‚îÇ + WAF       ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üöÄ **Tecnologias Utilizadas**

### **Infraestrutura**
- **Terraform**: Provisionamento de infraestrutura
- **Google Cloud Platform**: Cloud provider
- **Google Kubernetes Engine (GKE)**: Cluster Kubernetes gerenciado
- **VPC**: Rede privada com subnets customizadas

### **Containeriza√ß√£o e Orquestra√ß√£o**
- **Kubernetes**: Orquestra√ß√£o de containers
- **Docker**: Containeriza√ß√£o de aplica√ß√µes
- **Helm**: Gerenciamento de charts Kubernetes

### **Monitoramento e Observabilidade**
- **Prometheus**: Coleta e armazenamento de m√©tricas
- **Grafana**: Visualiza√ß√£o e dashboards
- **AlertManager**: Gerenciamento de alertas
- **Jaeger**: Distributed tracing (APM)
- **Kiali**: Visualiza√ß√£o do service mesh (APM)
- **Fluent Bit**: Agrega√ß√£o de logs

### **Seguran√ßa**
- **HashiCorp Vault**: Gerenciamento de secrets e keys
- **Cert-Manager**: Certificados SSL/TLS autom√°ticos
- **Network Policies**: Controle de tr√°fego entre pods
- **RBAC**: Controle de acesso baseado em roles
- **Cloud Armor**: Prote√ß√£o contra ataques web

### **Ingress e Load Balancing**
- **Nginx Ingress Controller**: Roteamento HTTP/HTTPS
- **Cloud Load Balancer**: Balanceamento de carga global
- **SSL/TLS**: Criptografia em tr√¢nsito

### **CI/CD e Automa√ß√£o**
- **Cloud Build**: Pipeline de build automatizado
- **Cloud Functions**: Automa√ß√£o serverless
- **Cloud Scheduler**: Jobs agendados
- **GitHub Integration**: Triggers autom√°ticos

## üìÅ **Estrutura do Projeto**

```
projeto-sre-devops/
‚îú‚îÄ‚îÄ Terraform/                          # Configura√ß√µes Terraform
‚îÇ   ‚îú‚îÄ‚îÄ main.tf                        # Infraestrutura principal
‚îÇ   ‚îú‚îÄ‚îÄ helm-monitoring.tf             # Stack de monitoramento
‚îÇ   ‚îú‚îÄ‚îÄ security-rbac.tf               # Seguran√ßa e RBAC
‚îÇ   ‚îú‚îÄ‚îÄ stress-testing.tf              # Testes de estresse
‚îÇ   ‚îú‚îÄ‚îÄ cicd-pipeline.tf               # Pipeline CI/CD
‚îÇ   ‚îú‚îÄ‚îÄ variables.tf                    # Vari√°veis
‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf                      # Outputs
‚îÇ   ‚îî‚îÄ‚îÄ service_account/                # Contas de servi√ßo
‚îú‚îÄ‚îÄ devops/                             # Manifests Kubernetes
‚îú‚îÄ‚îÄ sre/                                # Configura√ß√µes SRE
‚îú‚îÄ‚îÄ ingress-nginx-controller/           # Controlador Nginx
‚îú‚îÄ‚îÄ cloudbuild.yaml                     # Pipeline Cloud Build
‚îî‚îÄ‚îÄ README.md                           # Documenta√ß√£o
```

## üîß **Como Usar**

### **Pr√©-requisitos**
- Google Cloud SDK configurado
- Terraform >= 1.0
- kubectl configurado
- helm >= 3.0

### **Configura√ß√£o Inicial**
1. **Clone o reposit√≥rio**:
   ```bash
   git clone https://github.com/augustojoselg/projeto-sre-devops.git
   cd projeto-sre-devops
   ```

2. **Configure as vari√°veis**:
   ```bash
   cd Terraform
   cp variables.tf.example variables.tf
   # Edite variables.tf com seus valores
   ```

3. **Inicialize o Terraform**:
   ```bash
   terraform init
   terraform plan
   terraform apply
   ```

### **Deploy das Aplica√ß√µes**
1. **Configure o kubectl**:
   ```bash
   gcloud container clusters get-credentials <cluster-name> --region <region>
   ```

2. **Deploy do monitoramento**:
   ```bash
   kubectl apply -f Terraform/helm-monitoring.tf
   ```

3. **Deploy das aplica√ß√µes**:
   ```bash
   kubectl apply -f devops/
   kubectl apply -f sre/
   ```

## üåê **Acesso aos Servi√ßos**

### **Aplica√ß√£o Principal**
- **URL**: `https://<domain-name>`
- **Health Check**: `https://<domain-name>/health`

### **Monitoramento**
- **Grafana**: `http://<grafana-service-ip>:3000`
  - Usu√°rio: `seu usuario`
  - Senha: `sua senha`
- **Prometheus**: `http://<prometheus-service-ip>:9090`
- **AlertManager**: `http://<alertmanager-service-ip>:9093`

### **APM e Observabilidade**
- **Jaeger**: `https://jaeger.<domain-name>`
- **Kiali**: `http://<kiali-service-ip>:20001`

### **Secrets Management**
- **Vault**: `https://vault.<domain-name>`
  - Token: `seu token`

### **Testes de Estresse**
- **Resultados**: `https://stress-test.<domain-name>`

## üìä **Monitoramento e Alertas**

### **M√©tricas Coletadas**
- **Infraestrutura**: CPU, mem√≥ria, disco, rede
- **Aplica√ß√£o**: Response time, throughput, error rate
- **Kubernetes**: Pod status, node health, resource usage
- **Custom**: M√©tricas espec√≠ficas da aplica√ß√£o

### **Alertas Configurados**
- **Cluster Health**: Pods n√£o saud√°veis, nodes offline
- **Performance**: High response time, low throughput
- **Security**: Failed authentication, suspicious activity
- **Resources**: High CPU/memory usage, disk space
- **Availability**: Service downtime, health check failures

### **Dashboards Grafana**
- **Cluster Overview**: Vis√£o geral do cluster
- **Application Metrics**: M√©tricas da aplica√ß√£o
- **Infrastructure**: Recursos de infraestrutura
- **Security**: Logs de seguran√ßa e auditoria
- **Stress Test**: Resultados dos testes de estresse

## üîí **Seguran√ßa**

### **Camadas de Seguran√ßa**
1. **Network Level**: VPC, subnets, firewall rules
2. **Cluster Level**: RBAC, network policies, pod security
3. **Application Level**: Secrets management, SSL/TLS
4. **Infrastructure Level**: Cloud Armor, KMS encryption

### **Compliance**
- **GDPR**: Logs e dados anonimizados
- **SOC 2**: Auditoria e monitoramento
- **ISO 27001**: Gest√£o de seguran√ßa da informa√ß√£o
- **PCI DSS**: Prote√ß√£o de dados sens√≠veis

### **Vault Integration**
- **Secrets**: Credenciais de banco, API keys
- **Keys**: Chaves de criptografia
- **Certificates**: Certificados SSL/TLS
- **Dynamic Secrets**: Gera√ß√£o autom√°tica de credenciais

## üß™ **Testes de Estresse**

### **Ferramentas Utilizadas**
- **K6**: Testes de performance com JavaScript
- **Apache Bench (ab)**: Testes de carga b√°sicos
- **WRK**: Testes de alta concorr√™ncia
- **Vegeta**: Testes de taxa constante

### **Cen√°rios de Teste**
1. **Ramp Up**: Aumento gradual da carga (2 min)
2. **Sustained Load**: Carga constante (5 min)
3. **Peak Load**: Pico de carga (2 min)
4. **Ramp Down**: Redu√ß√£o gradual (3 min)

### **M√©tricas Monitoradas**
- **Response Time**: P50, P95, P99
- **Throughput**: Requests per second
- **Error Rate**: Taxa de erros
- **Resource Usage**: CPU, mem√≥ria, rede

### **Automa√ß√£o**
- **CronJob**: Execu√ß√£o autom√°tica a cada 6 horas
- **Monitoring**: M√©tricas em tempo real
- **Alerting**: Notifica√ß√µes autom√°ticas
- **Reporting**: Dashboards com resultados

## üîÑ **CI/CD Pipeline**

### **Fluxo do Pipeline**
1. **Code Push**: Trigger autom√°tico no GitHub
2. **Infrastructure**: Terraform plan/apply
3. **Application**: Deploy da aplica√ß√£o
4. **Monitoring**: Deploy do stack de monitoramento
5. **Testing**: Execu√ß√£o de testes de estresse
6. **Health Check**: Verifica√ß√£o de sa√∫de

### **Automa√ß√µes**
- **Backup**: Backup autom√°tico di√°rio
- **Security Scan**: Verifica√ß√£o de vulnerabilidades
- **Cleanup**: Limpeza de recursos obsoletos
- **Notifications**: Alertas por email/Slack

## üìà **Alta Disponibilidade**

### **Estrat√©gias Implementadas**
1. **Multi-Zone**: Distribui√ß√£o em m√∫ltiplas zonas
2. **Auto-Scaling**: Escalabilidade autom√°tica (2-5 nodes)
3. **Load Balancing**: Balanceamento global com health checks
4. **Redundancy**: M√∫ltiplas r√©plicas de aplica√ß√£o
5. **Auto-Recovery**: Recupera√ß√£o autom√°tica de falhas

### **SLA Objetivos**
- **Uptime**: 99.9% (8.76 horas de downtime por ano)
- **Recovery Time**: < 5 minutos para falhas simples
- **Data Loss**: 0% (backup autom√°tico)
- **Performance**: P95 < 500ms response time

## üí∞ **Otimiza√ß√£o de Custos**

### **Estrat√©gias de Economia**
1. **Spot Instances**: Uso de inst√¢ncias spot quando poss√≠vel
2. **Auto-Scaling**: Escala para baixo em per√≠odos de baixa demanda
3. **Resource Limits**: Limites de recursos para evitar overspending
4. **Monitoring**: Alertas de custo em tempo real
5. **Cleanup**: Remo√ß√£o autom√°tica de recursos n√£o utilizados

### **Estimativa de Custos**
- **GKE**: ~$150-300/m√™s (dependendo do uso)
- **Monitoring**: ~$50-100/m√™s
- **Storage**: ~$20-50/m√™s
- **Network**: ~$30-80/m√™s
- **Total Estimado**: ~$250-530/m√™s

## üö® **Troubleshooting**

### **Problemas Comuns**

#### **Cluster n√£o inicia**
```bash
# Verificar status do cluster
gcloud container clusters describe <cluster-name> --region <region>

# Verificar logs do master
gcloud logging read "resource.type=gke_cluster" --limit=50
```

#### **Pods n√£o iniciam**
```bash
# Verificar eventos dos pods
kubectl get events --sort-by='.lastTimestamp'

# Verificar logs dos pods
kubectl logs <pod-name> -n <namespace>
```

#### **Problemas de rede**
```bash
# Verificar pol√≠ticas de rede
kubectl get networkpolicies --all-namespaces

# Verificar configura√ß√£o do ingress
kubectl describe ingress <ingress-name> -n <namespace>
```

#### **Problemas de monitoramento**
```bash
# Verificar status do Prometheus
kubectl get pods -n monitoring

# Verificar logs do Grafana
kubectl logs -f deployment/grafana -n monitoring
```

### **Comandos √öteis**
```bash
# Status geral do cluster
kubectl get all --all-namespaces

# Verificar recursos
kubectl top nodes
kubectl top pods --all-namespaces

# Verificar logs de todos os pods
kubectl logs --all-containers=true --all-namespaces --tail=100

# Verificar eventos
kubectl get events --all-namespaces --sort-by='.lastTimestamp'
```

## üìö **Recursos Adicionais**

### **Documenta√ß√£o**
- [Terraform GCP Provider](https://registry.terraform.io/providers/hashicorp/google/latest/docs)
- [Kubernetes Documentation](https://kubernetes.io/docs/)
- [Prometheus Documentation](https://prometheus.io/docs/)
- [Grafana Documentation](https://grafana.com/docs/)
- [Vault Documentation](https://www.vaultproject.io/docs/)

### **Ferramentas Recomendadas**
- **k9s**: Terminal UI para Kubernetes
- **Lens**: IDE para Kubernetes
- **Octant**: Dashboard para Kubernetes
- **Popeye**: Auditoria de clusters Kubernetes

### **Comunidade**
- [Kubernetes Slack](https://slack.k8s.io/)
- [Terraform Community](https://discuss.hashicorp.com/)
- [Grafana Community](https://community.grafana.com/)

## ü§ù **Contribui√ß√£o**

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## üìÑ **Licen√ßa**

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## üìû **Suporte**

Para suporte e d√∫vidas:
- **Issues**: [GitHub Issues](https://github.com/username/repo/issues)
- **Email**: augustojoselg@sysmac-nf.com.br
- **Slack**: #sre-support

---

**Desenvolvido com ‚ù§Ô∏è pela equipe de SRE**
